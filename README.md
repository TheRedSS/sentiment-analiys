# Enhanced Sentiment Analysis with Data Augmentation

Bu proje, Go Emotions veri seti kullanarak 27 farklÄ± duygu tÃ¼rÃ¼nÃ¼ sÄ±nÄ±flandÄ±ran geliÅŸmiÅŸ bir duygu analizi modeli iÃ§erir. Model, veri artÄ±rma (Data Augmentation) teknikleri kullanÄ±larak geliÅŸtirilmiÅŸtir.

## ğŸš€ Ã–zellikler

- **27 Duygu SÄ±nÄ±fÄ±**: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral
- **GeliÅŸmiÅŸ Veri ArtÄ±rma**: Synonym replacement, random insertion, random swap, random deletion
- **Bidirectional GRU Model**: Ã‡ok katmanlÄ± derin Ã¶ÄŸrenme modeli
- **KapsamlÄ± DeÄŸerlendirme**: Accuracy, AUC, Precision, Recall metrikleri
- **GÃ¶rselleÅŸtirme**: Training history ve sonuÃ§ analizi grafikleri
- **Ã–zel Veri Testi**: Kendi verilerinizle model testi

## ğŸ“ Dosya YapÄ±sÄ±

```
sentiment-analysis/
â”œâ”€â”€ main_enhanced.py          # GeliÅŸmiÅŸ model eÄŸitimi
â”œâ”€â”€ text_processor.py         # Metin iÅŸleme ve veri artÄ±rma
â”œâ”€â”€ test_custom_data.py       # Ã–zel veri testi
â”œâ”€â”€ main.py                   # Orijinal model
â”œâ”€â”€ pred.py                   # Orijinal tahmin
â”œâ”€â”€ requirements.txt          # Gerekli kÃ¼tÃ¼phaneler
â”œâ”€â”€ README.md                 # Bu dosya
â”œâ”€â”€ sentiment_analysis_model.h5  # EÄŸitilmiÅŸ model
â”œâ”€â”€ tokenizer.pkl            # Tokenizer
â”œâ”€â”€ mlb.pkl                  # Label encoder
â””â”€â”€ best_model.h5            # En iyi model (eÄŸitim sÄ±rasÄ±nda)
```

## ğŸ› ï¸ Kurulum

1. **Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:**
```bash
pip install -r requirements.txt
```

2. **NLTK verilerini indirin:**
```python
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
```

## ğŸ¯ KullanÄ±m

### 1. Model EÄŸitimi

GeliÅŸmiÅŸ veri artÄ±rma teknikleriyle modeli eÄŸitin:

```bash
python main_enhanced.py
```

Bu script:
- 10,000 Ã¶rnek yÃ¼kler
- Veri artÄ±rma teknikleri uygular
- GeliÅŸmiÅŸ model mimarisi kullanÄ±r
- Training history grafiklerini oluÅŸturur
- 10 Ã¶zel test verisiyle modeli test eder

### 2. Ã–zel Veri Testi

Kendi verilerinizle modeli test edin:

```bash
python test_custom_data.py
```

Bu script:
- EÄŸitilmiÅŸ modeli yÃ¼kler
- 10 Ã¶zel test verisiyle tahmin yapar
- DetaylÄ± sonuÃ§ analizi sunar
- GÃ¶rselleÅŸtirmeler oluÅŸturur
- SonuÃ§larÄ± dosyaya kaydeder

### 3. Kendi Verilerinizi Test Etmek

`test_custom_data.py` dosyasÄ±ndaki `custom_texts` listesini deÄŸiÅŸtirin:

```python
custom_texts = [
    "Your custom text here",
    "Another custom text",
    # ... daha fazla metin
]
```

## ğŸ“Š Veri ArtÄ±rma Teknikleri

### 1. Synonym Replacement (EÅŸ AnlamlÄ± Kelime DeÄŸiÅŸtirme)
Kelimeleri WordNet kullanarak eÅŸ anlamlÄ±larÄ±yla deÄŸiÅŸtirir
- Ã–rnek: "happy" â†’ "joyful"

### 2. Random Insertion (Rastgele Ekleme)
Metindeki kelimeleri rastgele konumlara ekler
- Ã–rnek: "I am happy" â†’ "I am happy am"

### 3. Random Swap (Rastgele DeÄŸiÅŸtirme)
Kelime Ã§iftlerini rastgele deÄŸiÅŸtirir
- Ã–rnek: "I am happy" â†’ "am I happy"

### 4. Random Deletion (Rastgele Silme)
Kelimeleri belirli olasÄ±lÄ±kla siler
- Ã–rnek: "I am very happy" â†’ "I am happy"

### 5. Random Shuffle (Rastgele KarÄ±ÅŸtÄ±rma)
Kelimeleri rastgele sÄ±ralar
- Ã–rnek: "I am happy" â†’ "happy I am"

## ğŸ—ï¸ Model Mimarisi

```
Embedding (256d) â†’ SpatialDropout (0.3)
    â†“
Bidirectional GRU (256) â†’ LayerNormalization
    â†“
Bidirectional GRU (128) â†’ LayerNormalization
    â†“
Bidirectional GRU (64) â†’ LayerNormalization
    â†“
Dense (128) â†’ Dropout (0.5)
    â†“
Dense (64) â†’ Dropout (0.3)
    â†“
Dense (27, sigmoid)  # 27 duygu sÄ±nÄ±fÄ±
```

## ğŸ“ˆ Metrikler

Model ÅŸu metriklerle deÄŸerlendirilir:

- **Accuracy**: Genel doÄŸruluk oranÄ±
- **AUC**: ROC eÄŸrisi altÄ±ndaki alan
- **Precision**: Kesinlik
- **Recall**: DuyarlÄ±lÄ±k

## ğŸ“Š Ã‡Ä±ktÄ±lar

EÄŸitim sonrasÄ± oluÅŸturulan dosyalar:

- `training_history.png`: EÄŸitim geÃ§miÅŸi grafikleri
- `custom_data_heatmap.png`: Ã–zel veri sonuÃ§larÄ± heatmap
- `emotion_frequency.png`: Duygu frekans grafiÄŸi
- `custom_test_results.txt`: DetaylÄ± test sonuÃ§larÄ±

## ğŸ”§ Ã–zelleÅŸtirme

### Veri ArtÄ±rma Parametreleri
`text_processor.py` dosyasÄ±nda:
- `num_augmentations`: Her metin iÃ§in oluÅŸturulacak artÄ±rÄ±lmÄ±ÅŸ Ã¶rnek sayÄ±sÄ±
- `threshold`: Duygu tespiti iÃ§in gÃ¼ven eÅŸiÄŸi

### Model Parametreleri
`main_enhanced.py` dosyasÄ±nda:
- `epochs`: EÄŸitim epoch sayÄ±sÄ±
- `batch_size`: Batch boyutu
- `learning_rate`: Ã–ÄŸrenme oranÄ±

## ğŸš¨ Sorun Giderme

### Model YÃ¼kleme HatasÄ±
```
âœ— Error loading model. Please run main_enhanced.py first.
```
**Ã‡Ã¶zÃ¼m**: Ã–nce `main_enhanced.py` scriptini Ã§alÄ±ÅŸtÄ±rÄ±n.

### NLTK Veri HatasÄ±
```
LookupError: Resource stopwords not found
```
**Ã‡Ã¶zÃ¼m**: NLTK verilerini indirin:
```python
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
```

### Bellek HatasÄ±
**Ã‡Ã¶zÃ¼m**: Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n veya veri seti boyutunu azaltÄ±n.

## ğŸ“ Ã–rnek KullanÄ±m

```python
# Basit tahmin Ã¶rneÄŸi
import tensorflow as tf
import pickle

# Model yÃ¼kle
model = tf.keras.models.load_model("sentiment_analysis_model.h5")
with open("tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)
with open("mlb.pkl", "rb") as f:
    mlb = pickle.load(f)

# Metin iÅŸle
from text_processor import process_text
text = "I am feeling very happy today!"
clean_text = process_text(text)

# Tahmin yap
sequences = tokenizer.texts_to_sequences([clean_text])
X = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding="post", maxlen=100)
predictions = model.predict(X)

# SonuÃ§larÄ± gÃ¶ster
top_indices = np.argsort(predictions[0])[-3:][::-1]
for idx in top_indices:
    emotion = mlb.classes_[idx]
    confidence = predictions[0][idx]
    print(f"{emotion}: {confidence:.3f}")
```

## ğŸ¤ KatkÄ±da Bulunma

1. Bu repository'yi fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add some AmazingFeature'`)
4. Branch'inizi push edin (`git push origin feature/AmazingFeature`)
5. Pull Request oluÅŸturun

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ“ Ä°letiÅŸim

Proje Linki: [https://github.com/yourusername/sentiment-analysis](https://github.com/yourusername/sentiment-analysis)

---

â­ Bu projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!
