# ğŸ§  Ã‡ok SÄ±nÄ±flÄ± Duygu Analizi Projesi

Bu proje, **Go Emotions** veri seti kullanarak 27 farklÄ± duygu tÃ¼rÃ¼nÃ¼ sÄ±nÄ±flandÄ±ran geliÅŸmiÅŸ bir yapay zeka modeli sunar. Bidirectional GRU tabanlÄ± derin Ã¶ÄŸrenme mimarisi ve veri artÄ±rma teknikleri kullanÄ±larak geliÅŸtirilmiÅŸtir.

## ğŸŒŸ Proje Ã–zellikleri

### ğŸ¯ Ana Ã–zellikler
- **27 Duygu SÄ±nÄ±fÄ±**: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral
- **GeliÅŸmiÅŸ Veri ArtÄ±rma**: Synonym replacement, random insertion, random swap, random deletion teknikleri
- **Bidirectional GRU Modeli**: Ã‡ok katmanlÄ± derin Ã¶ÄŸrenme mimarisi
- **KapsamlÄ± DeÄŸerlendirme**: Accuracy, AUC, Precision, Recall metrikleri
- **GÃ¶rselleÅŸtirme**: EÄŸitim geÃ§miÅŸi ve sonuÃ§ analizi grafikleri
- **Ã–zel Veri Testi**: Kendi metinlerinizle model testi

### ğŸ”§ Teknik Ã–zellikler
- **GPU DesteÄŸi**: TensorFlow GPU optimizasyonu
- **Otomatik NLTK Kurulumu**: Gerekli dil iÅŸleme araÃ§larÄ±
- **Model Kaydetme**: En iyi modelin otomatik kaydedilmesi
- **Early Stopping**: AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nleme
- **Learning Rate Scheduling**: Dinamik Ã¶ÄŸrenme oranÄ± ayarlama

## ğŸ“ Proje YapÄ±sÄ±

```
sentiment-analiys/
â”œâ”€â”€ ğŸ“„ main_enhanced.py          # GeliÅŸmiÅŸ model eÄŸitimi ve ana script
â”œâ”€â”€ ğŸ“„ text_processor.py         # Metin iÅŸleme ve veri artÄ±rma sÄ±nÄ±fÄ±
â”œâ”€â”€ ğŸ“„ test_custom_data.py       # Ã–zel veri testi scripti
â”œâ”€â”€ ğŸ“„ main.py                   # Orijinal basit model
â”œâ”€â”€ ğŸ“„ pred.py                   # Orijinal tahmin scripti
â”œâ”€â”€ ğŸ“„ download_dataset.py       # Veri seti indirme scripti
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ ğŸ“„ README.md                 # Proje dokÃ¼mantasyonu
â”œâ”€â”€ ğŸ“Š go_emotions_dataset.csv   # Go Emotions veri seti
â”œâ”€â”€ ğŸ¯ best_model.h5            # En iyi eÄŸitilmiÅŸ model
â”œâ”€â”€ ğŸ”§ tokenizer.pkl            # Metin tokenizer'Ä±
â””â”€â”€ ğŸ·ï¸ mlb.pkl                  # Multi-label binarizer
```

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Ortam Kurulumu

```bash
# Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin
pip install -r requirements.txt

# NLTK verilerini indirin (otomatik olarak yapÄ±lÄ±r)
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('punkt'); nltk.download('averaged_perceptron_tagger')"
```

### 2. Model EÄŸitimi

```bash
# GeliÅŸmiÅŸ modeli eÄŸitin
python main_enhanced.py
```

Bu script ÅŸunlarÄ± yapar:
- âœ… 10,000 Ã¶rnek veri yÃ¼kler
- âœ… GeliÅŸmiÅŸ veri artÄ±rma teknikleri uygular
- âœ… Bidirectional GRU modelini eÄŸitir
- âœ… EÄŸitim geÃ§miÅŸi grafiklerini oluÅŸturur
- âœ… 10 Ã¶zel test verisiyle modeli deÄŸerlendirir

### 3. Ã–zel Veri Testi

```bash
# Kendi verilerinizle test edin
python test_custom_data.py
```

## ğŸ§® Veri ArtÄ±rma Teknikleri

### 1. Synonym Replacement (EÅŸ AnlamlÄ± DeÄŸiÅŸtirme)
```python
# Ã–rnek: "happy" â†’ "joyful"
text = "I am happy today"
augmented = "I am joyful today"
```

### 2. Random Insertion (Rastgele Ekleme)
```python
# Ã–rnek: "I am happy" â†’ "I am happy am"
text = "I am happy"
augmented = "I am happy am"
```

### 3. Random Swap (Rastgele DeÄŸiÅŸtirme)
```python
# Ã–rnek: "I am happy" â†’ "am I happy"
text = "I am happy"
augmented = "am I happy"
```

### 4. Random Deletion (Rastgele Silme)
```python
# Ã–rnek: "I am very happy" â†’ "I am happy"
text = "I am very happy"
augmented = "I am happy"
```

## ğŸ—ï¸ Model Mimarisi

```
ğŸ“¥ Input Text
    â†“
ğŸ”¤ Embedding Layer (256d)
    â†“
ğŸš« SpatialDropout (0.3)
    â†“
ğŸ”„ Bidirectional GRU (256 units)
    â†“
ğŸ“ LayerNormalization
    â†“
ğŸ”„ Bidirectional GRU (128 units)
    â†“
ğŸ“ LayerNormalization
    â†“
ğŸ”„ Bidirectional GRU (64 units)
    â†“
ğŸ“ LayerNormalization
    â†“
ğŸ§  Dense Layer (128 units)
    â†“
ğŸš« Dropout (0.5)
    â†“
ğŸ§  Dense Layer (64 units)
    â†“
ğŸš« Dropout (0.3)
    â†“
ğŸ¯ Output Layer (27 units, sigmoid)
```

## ğŸ“Š Performans Metrikleri

Model ÅŸu metriklerle deÄŸerlendirilir:

| Metrik | AÃ§Ä±klama |
|--------|----------|
| **Accuracy** | Genel doÄŸruluk oranÄ± |
| **AUC** | ROC eÄŸrisi altÄ±ndaki alan |
| **Precision** | Kesinlik (yanlÄ±ÅŸ pozitif oranÄ±) |
| **Recall** | DuyarlÄ±lÄ±k (yanlÄ±ÅŸ negatif oranÄ±) |

## ğŸ¨ Ã‡Ä±ktÄ± DosyalarÄ±

EÄŸitim sonrasÄ± oluÅŸturulan gÃ¶rselleÅŸtirmeler:

- ğŸ“ˆ `training_history.png`: EÄŸitim ve doÄŸrulama metrikleri
- ğŸ—ºï¸ `custom_data_heatmap.png`: Ã–zel veri sonuÃ§larÄ± heatmap
- ğŸ“Š `emotion_frequency.png`: Duygu daÄŸÄ±lÄ±m grafiÄŸi
- ğŸ“ `custom_test_results.txt`: DetaylÄ± test sonuÃ§larÄ±

## ğŸ’» KullanÄ±m Ã–rnekleri

### Basit Tahmin

```python
import tensorflow as tf
import pickle
import numpy as np

# Model ve tokenizer yÃ¼kle
model = tf.keras.models.load_model("best_model.h5")
with open("tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)
with open("mlb.pkl", "rb") as f:
    mlb = pickle.load(f)

# Metin iÅŸle
from text_processor import process_text
text = "I am feeling very happy today!"
clean_text = process_text(text)

# Tahmin yap
sequences = tokenizer.texts_to_sequences([clean_text])
X = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=100)
predictions = model.predict(X)

# En yÃ¼ksek 3 duyguyu gÃ¶ster
top_indices = np.argsort(predictions[0])[-3:][::-1]
for idx in top_indices:
    emotion = mlb.classes_[idx]
    confidence = predictions[0][idx]
    print(f"ğŸ­ {emotion}: {confidence:.3f}")
```

### Ã–zel Veri Testi

```python
# test_custom_data.py dosyasÄ±nÄ± dÃ¼zenleyin
custom_texts = [
    "Bu film gerÃ§ekten harika!",
    "Ã‡ok Ã¼zgÃ¼nÃ¼m bu durum iÃ§in.",
    "Yeni projeden heyecan duyuyorum!",
    "Bu davranÄ±ÅŸ beni kÄ±zdÄ±rÄ±yor.",
    "YardÄ±mÄ±n iÃ§in minnettarÄ±m."
]
```

## âš™ï¸ Ã–zelleÅŸtirme

### Veri ArtÄ±rma Parametreleri

`text_processor.py` dosyasÄ±nda:

```python
# Her metin iÃ§in oluÅŸturulacak artÄ±rÄ±lmÄ±ÅŸ Ã¶rnek sayÄ±sÄ±
num_augmentations = 3

# Duygu tespiti iÃ§in gÃ¼ven eÅŸiÄŸi
threshold = 0.3
```

### Model Parametreleri

`main_enhanced.py` dosyasÄ±nda:

```python
# EÄŸitim parametreleri
epochs = 50
batch_size = 32
learning_rate = 0.001
max_words = 10000
max_len = 100
embedding_dim = 256
```

## ğŸš¨ Sorun Giderme

### âŒ Model YÃ¼kleme HatasÄ±
```
Error loading model. Please run main_enhanced.py first.
```
**Ã‡Ã¶zÃ¼m**: Ã–nce `python main_enhanced.py` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.

### âŒ NLTK Veri HatasÄ±
```
LookupError: Resource stopwords not found
```
**Ã‡Ã¶zÃ¼m**: NLTK verilerini manuel olarak indirin:
```python
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
```

### âŒ Bellek HatasÄ±
**Ã‡Ã¶zÃ¼m**: 
- Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n: `batch_size = 16`
- Veri seti boyutunu azaltÄ±n: `sample_size = 5000`

### âŒ GPU HatasÄ±
**Ã‡Ã¶zÃ¼m**: CPU kullanÄ±mÄ±na geÃ§in:
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

## ğŸ”¬ Teknik Detaylar

### Veri Ä°ÅŸleme Pipeline
1. **Metin Temizleme**: KÃ¼Ã§Ã¼k harfe Ã§evirme, Ã¶zel karakter kaldÄ±rma
2. **Tokenization**: Kelime bazlÄ± tokenization
3. **Stop Word Removal**: Gereksiz kelimeleri kaldÄ±rma
4. **Lemmatization**: Kelime kÃ¶klerini bulma
5. **Veri ArtÄ±rma**: 4 farklÄ± teknik uygulama

### Model Optimizasyonu
- **Early Stopping**: AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nleme
- **Model Checkpoint**: En iyi modeli kaydetme
- **ReduceLROnPlateau**: Ã–ÄŸrenme oranÄ±nÄ± dinamik ayarlama
- **Layer Normalization**: EÄŸitim stabilizasyonu

## ğŸ¤ KatkÄ±da Bulunma

1. ğŸ´ Bu repository'yi fork edin
2. ğŸŒ¿ Feature branch oluÅŸturun: `git checkout -b feature/YeniOzellik`
3. ğŸ’¾ DeÄŸiÅŸikliklerinizi commit edin: `git commit -m 'Yeni Ã¶zellik eklendi'`
4. ğŸ“¤ Branch'inizi push edin: `git push origin feature/YeniOzellik`
5. ğŸ”„ Pull Request oluÅŸturun

## ğŸ“„ Lisans

Bu proje **MIT lisansÄ±** altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ“ Ä°letiÅŸim

- ğŸŒ **GitHub**: [Proje Linki](https://github.com/yourusername/sentiment-analiys)
- ğŸ“§ **E-posta**: your.email@example.com
- ğŸ’¬ **Issues**: GitHub Issues sayfasÄ±nÄ± kullanÄ±n


*Bu proje, doÄŸal dil iÅŸleme ve duygu analizi alanÄ±nda geliÅŸmiÅŸ teknikler kullanarak 27 farklÄ± duygu tÃ¼rÃ¼nÃ¼ sÄ±nÄ±flandÄ±rabilen gÃ¼Ã§lÃ¼ bir yapay zeka modeli sunar.*
